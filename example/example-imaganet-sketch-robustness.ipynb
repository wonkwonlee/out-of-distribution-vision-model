{"cells":[{"cell_type":"markdown","metadata":{"id":"2h6jJTmU2U41"},"source":["# List of Model Available "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dmshNv1ZlhZv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670976093684,"user_tz":300,"elapsed":5129,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"cd625fa2-5383-430d-c89f-67cc29856cc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[K     |████████████████████████████████| 549 kB 13.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 97.3 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3548,"status":"ok","timestamp":1670976106867,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"},"user_tz":300},"id":"n997uXMzlvJJ","outputId":"304fdf64-2cbd-466e-e8d7-2d95751c70cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["['adv_inception_v3', 'bat_resnext26ts', 'beit_base_patch16_224', 'beit_base_patch16_224_in22k', 'beit_base_patch16_384', 'beit_large_patch16_224', 'beit_large_patch16_224_in22k', 'beit_large_patch16_384', 'beit_large_patch16_512', 'beitv2_base_patch16_224', 'beitv2_base_patch16_224_in22k', 'beitv2_large_patch16_224', 'beitv2_large_patch16_224_in22k', 'botnet26t_256', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_tiny', 'coatnet_0_rw_224', 'coatnet_1_rw_224', 'coatnet_bn_0_rw_224', 'coatnet_nano_rw_224', 'coatnet_rmlp_1_rw_224', 'coatnet_rmlp_2_rw_224', 'coatnet_rmlp_nano_rw_224', 'coatnext_nano_rw_224', 'convit_base', 'convit_small', 'convit_tiny', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_atto', 'convnext_atto_ols', 'convnext_base', 'convnext_base_384_in22ft1k', 'convnext_base_in22ft1k', 'convnext_base_in22k', 'convnext_femto', 'convnext_femto_ols', 'convnext_large', 'convnext_large_384_in22ft1k', 'convnext_large_in22ft1k', 'convnext_large_in22k', 'convnext_nano', 'convnext_nano_ols', 'convnext_pico', 'convnext_pico_ols', 'convnext_small', 'convnext_small_384_in22ft1k', 'convnext_small_in22ft1k', 'convnext_small_in22k', 'convnext_tiny', 'convnext_tiny_384_in22ft1k', 'convnext_tiny_hnf', 'convnext_tiny_in22ft1k', 'convnext_tiny_in22k', 'convnext_xlarge_384_in22ft1k', 'convnext_xlarge_in22ft1k', 'convnext_xlarge_in22k', 'crossvit_9_240', 'crossvit_9_dagger_240', 'crossvit_15_240', 'crossvit_15_dagger_240', 'crossvit_15_dagger_408', 'crossvit_18_240', 'crossvit_18_dagger_240', 'crossvit_18_dagger_408', 'crossvit_base_240', 'crossvit_small_240', 'crossvit_tiny_240', 'cs3darknet_focus_l', 'cs3darknet_focus_m', 'cs3darknet_l', 'cs3darknet_m', 'cs3darknet_x', 'cs3edgenet_x', 'cs3se_edgenet_x', 'cs3sedarknet_l', 'cs3sedarknet_x', 'cspdarknet53', 'cspresnet50', 'cspresnext50', 'darknet53', 'darknetaa53', 'deit3_base_patch16_224', 'deit3_base_patch16_224_in21ft1k', 'deit3_base_patch16_384', 'deit3_base_patch16_384_in21ft1k', 'deit3_huge_patch14_224', 'deit3_huge_patch14_224_in21ft1k', 'deit3_large_patch16_224', 'deit3_large_patch16_224_in21ft1k', 'deit3_large_patch16_384', 'deit3_large_patch16_384_in21ft1k', 'deit3_medium_patch16_224', 'deit3_medium_patch16_224_in21ft1k', 'deit3_small_patch16_224', 'deit3_small_patch16_224_in21ft1k', 'deit3_small_patch16_384', 'deit3_small_patch16_384_in21ft1k', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'eca_resnet33ts', 'eca_resnext26ts', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet269d', 'ecaresnetlight', 'edgenext_base', 'edgenext_small', 'edgenext_small_rw', 'edgenext_x_small', 'edgenext_xx_small', 'efficientformer_l1', 'efficientformer_l3', 'efficientformer_l7', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_lite0', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'ens_adv_inception_resnet_v2', 'ese_vovnet19b_dw', 'ese_vovnet39b', 'fbnetc_100', 'fbnetv3_b', 'fbnetv3_d', 'fbnetv3_g', 'gc_efficientnetv2_rw_t', 'gcresnet33ts', 'gcresnet50t', 'gcresnext26ts', 'gcresnext50ts', 'gcvit_base', 'gcvit_small', 'gcvit_tiny', 'gcvit_xtiny', 'gcvit_xxtiny', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_100', 'gluon_inception_v3', 'gluon_resnet18_v1b', 'gluon_resnet34_v1b', 'gluon_resnet50_v1b', 'gluon_resnet50_v1c', 'gluon_resnet50_v1d', 'gluon_resnet50_v1s', 'gluon_resnet101_v1b', 'gluon_resnet101_v1c', 'gluon_resnet101_v1d', 'gluon_resnet101_v1s', 'gluon_resnet152_v1b', 'gluon_resnet152_v1c', 'gluon_resnet152_v1d', 'gluon_resnet152_v1s', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_senet154', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'gluon_xception65', 'gmixer_24_224', 'gmlp_s16_224', 'halo2botnet50ts_256', 'halonet26t', 'halonet50ts', 'haloregnetz_b', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w64', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'jx_nest_base', 'jx_nest_small', 'jx_nest_tiny', 'lambda_resnet26rpt_256', 'lambda_resnet26t', 'lambda_resnet50ts', 'lamhalobotnet50ts_256', 'lcnet_050', 'lcnet_075', 'lcnet_100', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'levit_128', 'levit_128s', 'levit_192', 'levit_256', 'levit_384', 'maxvit_nano_rw_256', 'maxvit_rmlp_nano_rw_256', 'maxvit_rmlp_pico_rw_256', 'maxvit_rmlp_small_rw_224', 'maxvit_rmlp_tiny_rw_256', 'maxvit_tiny_rw_224', 'maxxvit_rmlp_nano_rw_256', 'maxxvit_rmlp_small_rw_256', 'mixer_b16_224', 'mixer_b16_224_in21k', 'mixer_b16_224_miil', 'mixer_b16_224_miil_in21k', 'mixer_l16_224', 'mixer_l16_224_in21k', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mnasnet_100', 'mnasnet_small', 'mobilenetv2_050', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_100', 'mobilenetv3_large_100_miil', 'mobilenetv3_large_100_miil_in21k', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100', 'mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_150_384_in22ft1k', 'mobilevitv2_150_in22ft1k', 'mobilevitv2_175', 'mobilevitv2_175_384_in22ft1k', 'mobilevitv2_175_in22ft1k', 'mobilevitv2_200', 'mobilevitv2_200_384_in22ft1k', 'mobilevitv2_200_in22ft1k', 'mvitv2_base', 'mvitv2_large', 'mvitv2_small', 'mvitv2_tiny', 'nasnetalarge', 'nf_regnet_b1', 'nf_resnet50', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b2_li', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'regnetv_040', 'regnetv_064', 'regnetx_002', 'regnetx_004', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_064', 'regnety_080', 'regnety_120', 'regnety_160', 'regnety_320', 'regnetz_040', 'regnetz_040h', 'regnetz_b16', 'regnetz_c16', 'regnetz_c16_evos', 'regnetz_d8', 'regnetz_d8_evos', 'regnetz_d32', 'regnetz_e8', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net101_26w_4s', 'res2next50', 'resmlp_12_224', 'resmlp_12_224_dino', 'resmlp_12_distilled_224', 'resmlp_24_224', 'resmlp_24_224_dino', 'resmlp_24_distilled_224', 'resmlp_36_224', 'resmlp_36_distilled_224', 'resmlp_big_24_224', 'resmlp_big_24_224_in22ft1k', 'resmlp_big_24_distilled_224', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet10t', 'resnet14t', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet32ts', 'resnet33ts', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_gn', 'resnet50d', 'resnet51q', 'resnet61q', 'resnet101', 'resnet101d', 'resnet152', 'resnet152d', 'resnet200d', 'resnetaa50', 'resnetblur50', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50', 'resnetv2_50d_evos', 'resnetv2_50d_gn', 'resnetv2_50x1_bit_distilled', 'resnetv2_50x1_bitm', 'resnetv2_50x1_bitm_in21k', 'resnetv2_50x3_bitm', 'resnetv2_50x3_bitm_in21k', 'resnetv2_101', 'resnetv2_101x1_bitm', 'resnetv2_101x1_bitm_in21k', 'resnetv2_101x3_bitm', 'resnetv2_101x3_bitm_in21k', 'resnetv2_152x2_bit_teacher', 'resnetv2_152x2_bit_teacher_384', 'resnetv2_152x2_bitm', 'resnetv2_152x2_bitm_in21k', 'resnetv2_152x4_bitm', 'resnetv2_152x4_bitm_in21k', 'resnext26ts', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x8d', 'resnext101_64x4d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'sebotnet33ts_256', 'sehalonet33ts', 'selecsls42b', 'selecsls60', 'selecsls60b', 'semnasnet_075', 'semnasnet_100', 'sequencer2d_l', 'sequencer2d_m', 'sequencer2d_s', 'seresnet33ts', 'seresnet50', 'seresnet152d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26ts', 'seresnext50_32x4d', 'seresnext101_32x8d', 'seresnext101d_32x8d', 'seresnextaa101d_32x8d', 'skresnet18', 'skresnet34', 'skresnext50_32x4d', 'spnasnet_100', 'ssl_resnet18', 'ssl_resnet50', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swin_base_patch4_window7_224', 'swin_base_patch4_window7_224_in22k', 'swin_base_patch4_window12_384', 'swin_base_patch4_window12_384_in22k', 'swin_large_patch4_window7_224', 'swin_large_patch4_window7_224_in22k', 'swin_large_patch4_window12_384', 'swin_large_patch4_window12_384_in22k', 'swin_s3_base_224', 'swin_s3_small_224', 'swin_s3_tiny_224', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swinv2_base_window8_256', 'swinv2_base_window12_192_22k', 'swinv2_base_window12to16_192to256_22kft1k', 'swinv2_base_window12to24_192to384_22kft1k', 'swinv2_base_window16_256', 'swinv2_cr_small_224', 'swinv2_cr_small_ns_224', 'swinv2_cr_tiny_ns_224', 'swinv2_large_window12_192_22k', 'swinv2_large_window12to16_192to256_22kft1k', 'swinv2_large_window12to24_192to384_22kft1k', 'swinv2_small_window8_256', 'swinv2_small_window16_256', 'swinv2_tiny_window8_256', 'swinv2_tiny_window16_256', 'swsl_resnet18', 'swsl_resnet50', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tf_efficientnet_b0', 'tf_efficientnet_b0_ap', 'tf_efficientnet_b0_ns', 'tf_efficientnet_b1', 'tf_efficientnet_b1_ap', 'tf_efficientnet_b1_ns', 'tf_efficientnet_b2', 'tf_efficientnet_b2_ap', 'tf_efficientnet_b2_ns', 'tf_efficientnet_b3', 'tf_efficientnet_b3_ap', 'tf_efficientnet_b3_ns', 'tf_efficientnet_b4', 'tf_efficientnet_b4_ap', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b5', 'tf_efficientnet_b5_ap', 'tf_efficientnet_b5_ns', 'tf_efficientnet_b6', 'tf_efficientnet_b6_ap', 'tf_efficientnet_b6_ns', 'tf_efficientnet_b7', 'tf_efficientnet_b7_ap', 'tf_efficientnet_b7_ns', 'tf_efficientnet_b8', 'tf_efficientnet_b8_ap', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2_ns', 'tf_efficientnet_l2_ns_475', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_l_in21ft1k', 'tf_efficientnetv2_l_in21k', 'tf_efficientnetv2_m', 'tf_efficientnetv2_m_in21ft1k', 'tf_efficientnetv2_m_in21k', 'tf_efficientnetv2_s', 'tf_efficientnetv2_s_in21ft1k', 'tf_efficientnetv2_s_in21k', 'tf_efficientnetv2_xl_in21ft1k', 'tf_efficientnetv2_xl_in21k', 'tf_inception_v3', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tinynet_a', 'tinynet_b', 'tinynet_c', 'tinynet_d', 'tinynet_e', 'tnt_s_patch16_224', 'tresnet_l', 'tresnet_l_448', 'tresnet_m', 'tresnet_m_448', 'tresnet_m_miil_in21k', 'tresnet_v2_l', 'tresnet_xl', 'tresnet_xl_448', 'tv_densenet121', 'tv_resnet34', 'tv_resnet50', 'tv_resnet101', 'tv_resnet152', 'tv_resnext50_32x4d', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'vit_base_patch8_224', 'vit_base_patch8_224_dino', 'vit_base_patch8_224_in21k', 'vit_base_patch16_224', 'vit_base_patch16_224_dino', 'vit_base_patch16_224_in21k', 'vit_base_patch16_224_miil', 'vit_base_patch16_224_miil_in21k', 'vit_base_patch16_224_sam', 'vit_base_patch16_384', 'vit_base_patch16_rpn_224', 'vit_base_patch32_224', 'vit_base_patch32_224_clip_laion2b', 'vit_base_patch32_224_in21k', 'vit_base_patch32_224_sam', 'vit_base_patch32_384', 'vit_base_r50_s16_224_in21k', 'vit_base_r50_s16_384', 'vit_giant_patch14_224_clip_laion2b', 'vit_huge_patch14_224_clip_laion2b', 'vit_huge_patch14_224_in21k', 'vit_large_patch14_224_clip_laion2b', 'vit_large_patch16_224', 'vit_large_patch16_224_in21k', 'vit_large_patch16_384', 'vit_large_patch32_224_in21k', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_224_in21k', 'vit_large_r50_s32_384', 'vit_relpos_base_patch16_224', 'vit_relpos_base_patch16_clsgap_224', 'vit_relpos_base_patch32_plus_rpn_256', 'vit_relpos_medium_patch16_224', 'vit_relpos_medium_patch16_cls_224', 'vit_relpos_medium_patch16_rpn_224', 'vit_relpos_small_patch16_224', 'vit_small_patch8_224_dino', 'vit_small_patch16_224', 'vit_small_patch16_224_dino', 'vit_small_patch16_224_in21k', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_224_in21k', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_224_in21k', 'vit_small_r26_s32_384', 'vit_srelpos_medium_patch16_224', 'vit_srelpos_small_patch16_224', 'vit_tiny_patch16_224', 'vit_tiny_patch16_224_in21k', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_224_in21k', 'vit_tiny_r_s16_p8_384', 'volo_d1_224', 'volo_d1_384', 'volo_d2_224', 'volo_d2_384', 'volo_d3_224', 'volo_d3_448', 'volo_d4_224', 'volo_d4_448', 'volo_d5_224', 'volo_d5_448', 'volo_d5_512', 'wide_resnet50_2', 'wide_resnet101_2', 'xception', 'xception41', 'xception41p', 'xception65', 'xception65p', 'xception71', 'xcit_large_24_p8_224', 'xcit_large_24_p8_224_dist', 'xcit_large_24_p8_384_dist', 'xcit_large_24_p16_224', 'xcit_large_24_p16_224_dist', 'xcit_large_24_p16_384_dist', 'xcit_medium_24_p8_224', 'xcit_medium_24_p8_224_dist', 'xcit_medium_24_p8_384_dist', 'xcit_medium_24_p16_224', 'xcit_medium_24_p16_224_dist', 'xcit_medium_24_p16_384_dist', 'xcit_nano_12_p8_224', 'xcit_nano_12_p8_224_dist', 'xcit_nano_12_p8_384_dist', 'xcit_nano_12_p16_224', 'xcit_nano_12_p16_224_dist', 'xcit_nano_12_p16_384_dist', 'xcit_small_12_p8_224', 'xcit_small_12_p8_224_dist', 'xcit_small_12_p8_384_dist', 'xcit_small_12_p16_224', 'xcit_small_12_p16_224_dist', 'xcit_small_12_p16_384_dist', 'xcit_small_24_p8_224', 'xcit_small_24_p8_224_dist', 'xcit_small_24_p8_384_dist', 'xcit_small_24_p16_224', 'xcit_small_24_p16_224_dist', 'xcit_small_24_p16_384_dist', 'xcit_tiny_12_p8_224', 'xcit_tiny_12_p8_224_dist', 'xcit_tiny_12_p8_384_dist', 'xcit_tiny_12_p16_224', 'xcit_tiny_12_p16_224_dist', 'xcit_tiny_12_p16_384_dist', 'xcit_tiny_24_p8_224', 'xcit_tiny_24_p8_224_dist', 'xcit_tiny_24_p8_384_dist', 'xcit_tiny_24_p16_224', 'xcit_tiny_24_p16_224_dist', 'xcit_tiny_24_p16_384_dist']\n"]}],"source":["import timm\n","from pprint import pprint\n","model_names = timm.list_models(pretrained=True)\n","print(model_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24d93weNmRK4"},"outputs":[],"source":["#import timm\n","#model = timm.create_model('adv_inception_v3', pretrained=True)\n","#model.eval()\n"]},{"cell_type":"markdown","metadata":{"id":"dDHzcIhrzpnp"},"source":["## Imagenet - sketch Data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":936,"status":"ok","timestamp":1670976111335,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"},"user_tz":300},"id":"DVfUzHN8zrJE"},"outputs":[],"source":["import numpy as np\n","import sklearn.metrics as sk\n","recall_level_default = 0.95\n","\n","def calib_err(confidence, correct, p='2', beta=100):\n","    # beta is target bin size\n","    idxs = np.argsort(confidence)\n","    confidence = confidence[idxs]\n","    correct = correct[idxs]\n","    bins = [[i * beta, (i + 1) * beta] for i in range(len(confidence) // beta)]\n","    bins[-1] = [bins[-1][0], len(confidence)]\n","\n","    cerr = 0\n","    total_examples = len(confidence)\n","    for i in range(len(bins) - 1):\n","        bin_confidence = confidence[bins[i][0]:bins[i][1]]\n","        bin_correct = correct[bins[i][0]:bins[i][1]]\n","        num_examples_in_bin = len(bin_confidence)\n","\n","        if num_examples_in_bin > 0:\n","            difference = np.abs(np.nanmean(bin_confidence) - np.nanmean(bin_correct))\n","\n","            if p == '2':\n","                cerr += num_examples_in_bin / total_examples * np.square(difference)\n","            elif p == '1':\n","                cerr += num_examples_in_bin / total_examples * difference\n","            elif p == 'infty' or p == 'infinity' or p == 'max':\n","                cerr = np.maximum(cerr, difference)\n","            else:\n","                assert False, \"p must be '1', '2', or 'infty'\"\n","\n","    if p == '2':\n","        cerr = np.sqrt(cerr)\n","\n","    return cerr\n","\n","\n","def aurra(confidence, correct):\n","    conf_ranks = np.argsort(confidence)[::-1]  # indices from greatest to least confidence\n","    rra_curve = np.cumsum(np.asarray(correct)[conf_ranks])\n","    rra_curve = rra_curve / np.arange(1, len(rra_curve) + 1)  # accuracy at each response rate\n","    return np.mean(rra_curve)\n","\n","\n","def soft_f1(confidence, correct):\n","    wrong = 1 - correct\n","\n","    # # the incorrectly classified samples are our interest\n","    # # so they make the positive class\n","    # tp_soft = np.sum((1 - confidence) * wrong)\n","    # fp_soft = np.sum((1 - confidence) * correct)\n","    # fn_soft = np.sum(confidence * wrong)\n","\n","    # return 2 * tp_soft / (2 * tp_soft + fn_soft + fp_soft)\n","    return 2 * ((1 - confidence) * wrong).sum()/(1 - confidence + wrong).sum()\n","\n","\n","def tune_temp(logits, labels, binary_search=True, lower=0.2, upper=5.0, eps=0.0001):\n","    logits = np.array(logits)\n","\n","    if binary_search:\n","        import torch\n","        import torch.nn.functional as F\n","\n","        logits = torch.FloatTensor(logits)\n","        labels = torch.LongTensor(labels)\n","        t_guess = torch.FloatTensor([0.5*(lower + upper)]).requires_grad_()\n","\n","        while upper - lower > eps:\n","            if torch.autograd.grad(F.cross_entropy(logits / t_guess, labels), t_guess)[0] > 0:\n","                upper = 0.5 * (lower + upper)\n","            else:\n","                lower = 0.5 * (lower + upper)\n","            t_guess = t_guess * 0 + 0.5 * (lower + upper)\n","\n","        t = min([lower, 0.5 * (lower + upper), upper], key=lambda x: float(F.cross_entropy(logits / x, labels)))\n","    else:\n","        import cvxpy as cx\n","\n","        set_size = np.array(logits).shape[0]\n","\n","        t = cx.Variable()\n","\n","        expr = sum((cx.Minimize(cx.log_sum_exp(logits[i, :] * t) - logits[i, labels[i]] * t)\n","                    for i in range(set_size)))\n","        p = cx.Problem(expr, [lower <= t, t <= upper])\n","\n","        p.solve()   # p.solve(solver=cx.SCS)\n","        t = 1 / t.value\n","\n","    return t\n","\n","\n","def print_measures(rms, aurra_metric, mad, sf1, method_name='Baseline'):\n","    print('\\t\\t\\t\\t\\t\\t\\t' + method_name)\n","    print('RMS Calib Error (%): \\t\\t{:.2f}'.format(100 * rms))\n","    print('AURRA (%): \\t\\t\\t{:.2f}'.format(100 * aurra))\n","    # print('MAD Calib Error (%): \\t\\t{:.2f}'.format(100 * mad))\n","    # print('Soft F1 Score (%):   \\t\\t{:.2f}'.format(100 * sf1))\n","\n","\n","def show_calibration_results(confidence, correct, method_name='Baseline'):\n","\n","    print('\\t\\t\\t\\t' + method_name)\n","    print('RMS Calib Error (%): \\t\\t{:.2f}'.format(\n","        100 * calib_err(confidence, correct, p='2')))\n","\n","    print('AURRA (%): \\t\\t\\t{:.2f}'.format(\n","        100 * aurra(confidence, correct)))\n","\n","    # print('MAD Calib Error (%): \\t\\t{:.2f}'.format(\n","    #     100 * calib_err(confidence, correct, p='1')))\n","\n","    # print('Soft F1-Score (%): \\t\\t{:.2f}'.format(\n","    #     100 * soft_f1(confidence, correct)))\n","\n","def fpr_and_fdr_at_recall(y_true, y_score, recall_level=recall_level_default, pos_label=None):\n","    classes = np.unique(y_true)\n","    if (pos_label is None and\n","            not (np.array_equal(classes, [0, 1]) or\n","                     np.array_equal(classes, [-1, 1]) or\n","                     np.array_equal(classes, [0]) or\n","                     np.array_equal(classes, [-1]) or\n","                     np.array_equal(classes, [1]))):\n","        raise ValueError(\"Data is not binary and pos_label is not specified\")\n","    elif pos_label is None:\n","        pos_label = 1.\n","\n","    # make y_true a boolean vector\n","    y_true = (y_true == pos_label)\n","\n","    # sort scores and corresponding truth values\n","    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n","    y_score = y_score[desc_score_indices]\n","    y_true = y_true[desc_score_indices]\n","\n","    # y_score typically has many tied values. Here we extract\n","    # the indices associated with the distinct values. We also\n","    # concatenate a value for the end of the curve.\n","    distinct_value_indices = np.where(np.diff(y_score))[0]\n","    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n","\n","    # accumulate the true positives with decreasing threshold\n","    tps = stable_cumsum(y_true)[threshold_idxs]\n","    fps = 1 + threshold_idxs - tps      # add one because of zero-based indexing\n","\n","    thresholds = y_score[threshold_idxs]\n","\n","    recall = tps / tps[-1]\n","\n","    last_ind = tps.searchsorted(tps[-1])\n","    sl = slice(last_ind, None, -1)      # [last_ind::-1]\n","    recall, fps, tps, thresholds = np.r_[recall[sl], 1], np.r_[fps[sl], 0], np.r_[tps[sl], 0], thresholds[sl]\n","\n","    cutoff = np.argmin(np.abs(recall - recall_level))\n","\n","    return fps[cutoff] / (np.sum(np.logical_not(y_true)))   # , fps[cutoff]/(fps[cutoff] + tps[cutoff])\n","\n","def get_measures(_pos, _neg, recall_level=recall_level_default):\n","    pos = np.array(_pos[:]).reshape((-1, 1))\n","    neg = np.array(_neg[:]).reshape((-1, 1))\n","    examples = np.squeeze(np.vstack((pos, neg)))\n","    labels = np.zeros(len(examples), dtype=np.int32)\n","    labels[:len(pos)] += 1\n","\n","    auroc = sk.roc_auc_score(labels, examples)\n","    aupr = sk.average_precision_score(labels, examples)\n","    fpr = fpr_and_fdr_at_recall(labels, examples, recall_level)\n","\n","    return auroc, aupr, fpr\n","\n","\n","def print_measures_old(auroc, aupr, fpr, method_name='Ours', recall_level=recall_level_default):\n","    print('\\t\\t\\t' + method_name)\n","    print('FPR{:d}:\\t{:.2f}'.format(int(100 * recall_level), 100 * fpr))\n","    print('AUROC: \\t{:.2f}'.format(100 * auroc))\n","    print('AUPR:  \\t{:.2f}'.format(100 * aupr))\n","\n","\n","def print_measures_with_std(aurocs, auprs, fprs, method_name='Ours', recall_level=recall_level_default):\n","    print('\\t\\t\\t' + method_name)\n","    print('FPR{:d}:\\t{:.2f}\\t+/- {:.2f}'.format(int(100 * recall_level), 100 * np.mean(fprs), 100 * np.std(fprs)))\n","    print('AUROC: \\t{:.2f}\\t+/- {:.2f}'.format(100 * np.mean(aurocs), 100 * np.std(aurocs)))\n","    print('AUPR:  \\t{:.2f}\\t+/- {:.2f}'.format(100 * np.mean(auprs), 100 * np.std(auprs)))\n","\n","\n","def get_and_print_results(out_score, in_score, num_to_avg=1):\n","\n","    aurocs, auprs, fprs = [], [], []\n","    #for _ in range(num_to_avg):\n","    #    out_score = get_ood_scores(ood_loader)\n","    measures = get_measures(out_score, in_score)\n","    aurocs.append(measures[0]); auprs.append(measures[1]); fprs.append(measures[2])\n","\n","    auroc = np.mean(aurocs); aupr = np.mean(auprs); fpr = np.mean(fprs)\n","    #auroc_list.append(auroc); aupr_list.append(aupr); fpr_list.append(fpr)\n","\n","    #if num_to_avg >= 5:\n","    #    print_measures_with_std(aurocs, auprs, fprs, method_name='Ours')\n","    #else:\n","    #    print_measures(auroc, aupr, fpr, method_name='Ours')\n","    return auroc, aupr, fpr "]},{"cell_type":"markdown","metadata":{"id":"FQPr_8jr4d-P"},"source":["# Imagenet - sketch: Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddj8XMujF_33"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SGN_nrLrCuP-","executionInfo":{"status":"ok","timestamp":1670976261403,"user_tz":300,"elapsed":144157,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dset\n","import torchvision.transforms as trn\n","import torchvision.transforms.functional as trnF\n","import torchvision.models as models\n","import torch.utils.model_zoo as model_zoo\n","import torch.nn.functional as F\n","import numpy as np\n","\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","test_transform = trn.Compose(\n","    [trn.Resize(256), trn.CenterCrop(224), trn.ToTensor(), trn.Normalize(mean, std)])\n","\n","\n","PATH_TO_IMAGENET_SKETCH = \"/content/drive/MyDrive/vision_project/sketch\"\n","\n","imagenet_sketch = dset.ImageFolder(root=PATH_TO_IMAGENET_SKETCH, transform=test_transform)\n","nae_loader_sketch = torch.utils.data.DataLoader(imagenet_sketch, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kRvF9YGB97Gp","executionInfo":{"status":"ok","timestamp":1670976411364,"user_tz":300,"elapsed":238,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["concat = lambda x: np.concatenate(x, axis=0)\n","to_np = lambda x: x.data.to('cpu').numpy()\n","def get_predictions_sketch(loader, net=None, num_cls=1000):\n","    net = timm.create_model(net, pretrained=True, num_classes=num_cls)\n","    net.cuda()\n","    net.eval()\n","    confidence = []\n","    correct = []\n","    num_correct = 0\n","    with torch.no_grad():\n","        for data, target in loader:\n","            data, target = data.cuda(), target.cuda()\n","            output = net(data)\n","\n","            # accuracy\n","            pred = output.data.max(1)[1]\n","            num_correct += pred.eq(target.data).sum().item()\n","\n","            confidence.extend(to_np(F.softmax(output, dim=1).max(1)[0]).squeeze().tolist())\n","            pred = output.data.max(1)[1]\n","            correct.extend(pred.eq(target).to('cpu').numpy().squeeze().tolist())\n","\n","    return np.array(confidence), np.array(correct), num_correct\n","\n","def get_imagenet_sketch_results(loader, net=None, num_cls=1000):\n","    confidence, correct, num_correct = get_predictions_sketch(loader, net, num_cls)\n","    acc = num_correct / len(loader.dataset)\n","    print('Accuracy (%):', round(100*acc, 2))\n","    #show_calibration_results(confidence, correct)\n","    return acc, confidence.copy(), correct.copy()"]},{"cell_type":"markdown","metadata":{"id":"I_GPaqtY4f-i"},"source":["# Example"]},{"cell_type":"markdown","metadata":{"id":"jLo138mR6y8x"},"source":["# Recipe - 1 Running - CNN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-boufurJ60Hu"},"outputs":[],"source":["cnn_model_lst1 = ['cspresnet50', 'densenet121', 'dla34', 'dpn68', 'efficientnetv2_rw_m',\n","                  'efficientnet_b0', 'mixnet_l', 'mnasnet_100', 'fbnetc_100', 'spnasnet_100', 'tinynet_a',\n","                 'ghostnet_100', 'hrnet_w18', 'inception_resnet_v2', 'inception_v3', 'nasnetalarge', 'nf_resnet50', 'pnasnet5large',\n","                 'res2net50_14w_8s', 'resnest14d', 'resnet10t', 'rexnet_100', 'selecsls42b', 'skresnet18',\n","                  'tnt_s_patch16_224', 'vgg19', 'ese_vovnet19b_dw', 'xception']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sZjlzSKCYkJ"},"outputs":[],"source":["cnn_model_lst1 = ['selecsls42b', 'skresnet18',\n","                  'tnt_s_patch16_224', 'vgg19', 'ese_vovnet19b_dw', 'xception']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1670964401639,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"},"user_tz":300},"id":"1wr9Rveqs3HR","outputId":"0e97c02a-0764-4bed-9cde-fa5b8055f5c4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":40}],"source":["len(cnn_model_lst1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2298568,"status":"ok","timestamp":1670966706781,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"},"user_tz":300},"id":"mDhVDNPo-UYt","outputId":"7571fe0b-cb08-4072-8458-2f54edc47a44"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-selecsls/selecsls42b-8af30141.pth\" to /root/.cache/torch/hub/checkpoints/selecsls42b-8af30141.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 23.98\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/skresnet18_ra-4eec2804.pth\" to /root/.cache/torch/hub/checkpoints/skresnet18_ra-4eec2804.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 24.88\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/contrastive/pytorch-image-models/releases/download/TNT/tnt_s_patch16_224.pth.tar\" to /root/.cache/torch/hub/checkpoints/tnt_s_patch16_224.pth.tar\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 21.03\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 17.94\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/ese_vovnet19b_dw-a8741004.pth\" to /root/.cache/torch/hub/checkpoints/ese_vovnet19b_dw-a8741004.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 23.84\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth\" to /root/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 18.26\n"]}],"source":["cnn_accuracy = []\n","for name in cnn_model_lst1:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  cnn_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":817,"status":"ok","timestamp":1670967647420,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"},"user_tz":300},"id":"GJUUVU5DALiP","outputId":"e2843efb-8d70-4772-e635-f25388957124"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for selecsls42b model: 23.9777',\n"," 'ImageNet-Sketch Accuracy (%) for skresnet18 model: 24.8816',\n"," 'ImageNet-Sketch Accuracy (%) for tnt_s_patch16_224 model: 21.0281',\n"," 'ImageNet-Sketch Accuracy (%) for vgg19 model: 17.9371',\n"," 'ImageNet-Sketch Accuracy (%) for ese_vovnet19b_dw model: 23.8441',\n"," 'ImageNet-Sketch Accuracy (%) for xception model: 18.2554']"]},"metadata":{},"execution_count":42}],"source":["cnn_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjzkNboVqz76"},"outputs":[],"source":["## ignor\n","#cnn_model_lst2 = ['efficientnet_b0', 'mixnet_l', 'mnasnet_100', 'fbnetc_100', 'spnasnet_100', 'tinynet_a',\n","#                 'ghostnet_100', 'hrnet_w18', 'inception_resnet_v2', 'nasnetalarge', 'pnasnet5large',\n","#                 'res2net50_14w_8s', 'resnest14d', 'resnet10t', 'rexnet_100', 'selecsls42b', 'skresnet18',\n","#                  'tnt_s_patch16_224', 'vgg19', 'ese_vovnet19b_dw', 'xception']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQvGCkmWIO1d"},"outputs":[],"source":["#cnn_accuracy2 = []\n","\n","#for name in cnn_model_lst2:\n","#  acc, test_confidence, test_correct = get_net_results(model_name= name)\n","#  value = f'ImageNet-A Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","#  cnn_accuracy2.append(value)\n","#  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mmc5fL1qrCvj"},"outputs":[],"source":["#cnn_accuracy2"]},{"cell_type":"markdown","metadata":{"id":"5_4GAtu3B-Wm"},"source":["# Recipe - 2 - Running - Vision Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OL8WF_UVGo5h"},"outputs":[],"source":["## vit_large_patch16_384 = An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CQY0r7rCCKm"},"outputs":[],"source":["## divide the model by 4-5 \n","vit_model_lst = ['beit_base_patch16_224', 'cait_s24_224', 'coatnet_0_rw_224', 'crossvit_base_240', \n","                 'deit_base_patch16_224', 'deit3_base_patch16_224', 'efficientformer_l1', 'gcvit_base',\n","                 'maxvit_tiny_rw_224', 'mobilevit_s', 'mvitv2_base', 'jx_nest_base', 'pit_b_224', 'pvt_v2_b0', 'swin_s3_base_224', 'swinv2_cr_small_224', 'tnt_s_patch16_224', 'twins_pcpvt_base',\n","                 'visformer_small', 'vit_base_patch32_224', 'volo_d1_224', 'xcit_small_12_p8_224']"]},{"cell_type":"code","source":["vit_model_lst = ['jx_nest_base', \n","                 'pit_b_224', 'pvt_v2_b0', 'swin_s3_base_224', 'swinv2_cr_small_224', 'tnt_s_patch16_224', 'twins_pcpvt_base',\n","                 'visformer_small', 'vit_base_patch32_224', 'volo_d1_224', 'xcit_small_12_p8_224']"],"metadata":{"id":"WoyIwmt0cStv","executionInfo":{"status":"ok","timestamp":1670976434846,"user_tz":300,"elapsed":3,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nrmKsZqcCEyo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a47670a4-4501-4554-a109-0940cac594b0","executionInfo":{"status":"ok","timestamp":1670987135240,"user_tz":300,"elapsed":10694517,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/jx_nest_base-8bc41011.pth\" to /root/.cache/torch/hub/checkpoints/jx_nest_base-8bc41011.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 33.36\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-pit-weights/pit_b_820.pth\" to /root/.cache/torch/hub/checkpoints/pit_b_820.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 32.7\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b0.pth\" to /root/.cache/torch/hub/checkpoints/pvt_v2_b0.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 21.72\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/s3_b-a1e95db4.pth\" to /root/.cache/torch/hub/checkpoints/s3_b-a1e95db4.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 34.37\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights-swinv2/swin_v2_cr_small_224-0813c165.pth\" to /root/.cache/torch/hub/checkpoints/swin_v2_cr_small_224-0813c165.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 30.99\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/contrastive/pytorch-image-models/releases/download/TNT/tnt_s_patch16_224.pth.tar\" to /root/.cache/torch/hub/checkpoints/tnt_s_patch16_224.pth.tar\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 21.03\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/twins_pcpvt_base-e5ecb09b.pth\" to /root/.cache/torch/hub/checkpoints/twins_pcpvt_base-e5ecb09b.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 32.57\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vt3p-weights/visformer_small-839e1f5b.pth\" to /root/.cache/torch/hub/checkpoints/visformer_small-839e1f5b.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 30.11\n","Accuracy (%): 17.36\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/sail-sg/volo/releases/download/volo_1/d1_224_84.2.pth.tar\" to /root/.cache/torch/hub/checkpoints/d1_224_84.2.pth.tar\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 36.11\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://dl.fbaipublicfiles.com/xcit/xcit_small_12_p8_224.pth\" to /root/.cache/torch/hub/checkpoints/xcit_small_12_p8_224.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 34.53\n"]}],"source":["vit_accuracy = []\n","\n","for name in vit_model_lst:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  vit_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Pch8qVsSCGVw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670987305883,"user_tz":300,"elapsed":290,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"ff0cc25a-497d-467b-bfb5-117c029ec3b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for jx_nest_base model: 33.3569',\n"," 'ImageNet-Sketch Accuracy (%) for pit_b_224 model: 32.6986',\n"," 'ImageNet-Sketch Accuracy (%) for pvt_v2_b0 model: 21.7238',\n"," 'ImageNet-Sketch Accuracy (%) for swin_s3_base_224 model: 34.367',\n"," 'ImageNet-Sketch Accuracy (%) for swinv2_cr_small_224 model: 30.991',\n"," 'ImageNet-Sketch Accuracy (%) for tnt_s_patch16_224 model: 21.0281',\n"," 'ImageNet-Sketch Accuracy (%) for twins_pcpvt_base model: 32.5729',\n"," 'ImageNet-Sketch Accuracy (%) for visformer_small model: 30.1126',\n"," 'ImageNet-Sketch Accuracy (%) for vit_base_patch32_224 model: 17.3633',\n"," 'ImageNet-Sketch Accuracy (%) for volo_d1_224 model: 36.108',\n"," 'ImageNet-Sketch Accuracy (%) for xcit_small_12_p8_224 model: 34.532']"]},"metadata":{},"execution_count":9}],"source":["vit_accuracy"]},{"cell_type":"markdown","metadata":{"id":"tm2qUb69jL6A"},"source":["# Recipe - 3 - Combination of CNN and Vision Transformer"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9GWU0WBOjOwa","executionInfo":{"status":"ok","timestamp":1670987626735,"user_tz":300,"elapsed":293,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["combine_model_lst = ['convnext_base', 'convit_base', 'edgenext_base', 'levit_128']"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"b77R5tqLjOzT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670990257995,"user_tz":300,"elapsed":2625611,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"a69d9ad6-f652-4857-f597-c5d05dfd4523"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224_ema.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base_1k_224_ema.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 38.22\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://dl.fbaipublicfiles.com/convit/convit_base.pth\" to /root/.cache/torch/hub/checkpoints/convit_base.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 35.53\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/mmaaz60/EdgeNeXt/releases/download/v1.2/edgenext_base_usi.pth\" to /root/.cache/torch/hub/checkpoints/edgenext_base_usi.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 37.13\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://dl.fbaipublicfiles.com/LeViT/LeViT-128-b88c2750.pth\" to /root/.cache/torch/hub/checkpoints/LeViT-128-b88c2750.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 26.39\n"]}],"source":["combine_accuracy = []\n","\n","for name in combine_model_lst:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  combine_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O0iamhk7jr_p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670990575489,"user_tz":300,"elapsed":238,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"0bd0f499-ab2f-44b1-81d6-21d718f0c27f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for convnext_base model: 38.2244',\n"," 'ImageNet-Sketch Accuracy (%) for convit_base model: 35.5303',\n"," 'ImageNet-Sketch Accuracy (%) for edgenext_base model: 37.1298',\n"," 'ImageNet-Sketch Accuracy (%) for levit_128 model: 26.3927']"]},"metadata":{},"execution_count":12}],"source":["combine_accuracy"]},{"cell_type":"markdown","metadata":{"id":"tTiBWIBm2Jbn"},"source":["# Recipe - 4 - Running MLP Mixer"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"VpYxGfhs2LCf","executionInfo":{"status":"ok","timestamp":1670990581609,"user_tz":300,"elapsed":542,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["mlp_model_lst = ['mixer_b16_224']"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"aIKYZXfA2LEk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670991047609,"user_tz":300,"elapsed":462673,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"38eef99e-292b-453e-9ede-62355b3dfd84"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_mixer_b16_224-76587d61.pth\" to /root/.cache/torch/hub/checkpoints/jx_mixer_b16_224-76587d61.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 19.32\n"]}],"source":["mlp_accuracy = []\n","\n","for name in mlp_model_lst:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  mlp_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"HgkB2ZDw2NwK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670991772248,"user_tz":300,"elapsed":564,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"dcda0dbf-fb08-4be8-f5dd-a0c55cf40534"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for mixer_b16_224 model: 19.3224']"]},"metadata":{},"execution_count":15}],"source":["mlp_accuracy"]},{"cell_type":"markdown","metadata":{"id":"qHMVKqcIdm8A"},"source":["# 5.    Recipe - 5 - Mobilenet"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"f_U0u_lSdsee","executionInfo":{"status":"ok","timestamp":1670991778652,"user_tz":300,"elapsed":217,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["mobilenet_model_lst = ['mobilenetv3_large_100']"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"CAzrZ7k3dsg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670992130994,"user_tz":300,"elapsed":348351,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"d5776f2e-cf51-4a5c-bb25-5b1268aa73cf"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/mobilenetv3_large_100_ra-f55367f5.pth\" to /root/.cache/torch/hub/checkpoints/mobilenetv3_large_100_ra-f55367f5.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 22.95\n"]}],"source":["mobilenet_accuracy = []\n","\n","for name in mobilenet_model_lst:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  mobilenet_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"SMZhDSwEdtmP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670993825725,"user_tz":300,"elapsed":801,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"40c947d4-17b1-422f-f129-1143f0d8a439"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for mobilenetv3_large_100 model: 22.9499']"]},"metadata":{},"execution_count":18}],"source":["mobilenet_accuracy"]},{"cell_type":"markdown","metadata":{"id":"w88C3570duAm"},"source":["# 6.  Recipe - 6 - Others"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"_Wz3h4kkdxKZ","executionInfo":{"status":"ok","timestamp":1670993833093,"user_tz":300,"elapsed":639,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}}},"outputs":[],"source":["others_model_lst = ['regnetv_040', 'sequencer2d_l']"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"BX1VIEDNdxRT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670995103339,"user_tz":300,"elapsed":1268818,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"f82e7980-15c2-4b30-ee58-c50d7035c8f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tpu-weights/regnetv_040_ra3-c248f51f.pth\" to /root/.cache/torch/hub/checkpoints/regnetv_040_ra3-c248f51f.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 32.93\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth\" to /root/.cache/torch/hub/checkpoints/sequencer2d_l.pth\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy (%): 35.87\n"]}],"source":["others_accuracy = []\n","\n","for name in others_model_lst:\n","  acc, test_confidence, test_correct = get_imagenet_sketch_results(loader = nae_loader_sketch,net= name)\n","  value = f'ImageNet-Sketch Accuracy (%) for {name} model: {round(100*acc, 4)}'\n","  others_accuracy.append(value)\n","  #show_calibration_results(np.array(test_confidence), np.array(test_correct))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"I400PdMQdxXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670995525420,"user_tz":300,"elapsed":253,"user":{"displayName":"Salman Rahman","userId":"13852347893375027407"}},"outputId":"7e23c4c9-2ef8-45c7-fbb2-7a5f51bf97fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ImageNet-Sketch Accuracy (%) for regnetv_040 model: 32.9285',\n"," 'ImageNet-Sketch Accuracy (%) for sequencer2d_l model: 35.8683']"]},"metadata":{},"execution_count":21}],"source":["others_accuracy"]},{"cell_type":"markdown","metadata":{"id":"Fq43YkDIdxuy"},"source":["# 7.  Recipe - 7 - Perceiver"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZfSY7A8d1bh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_pgXWeud1ek"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_BjCzIqd1nZ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"kaZnh628NSXt"},"source":["# Cross Checking Model Name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aiwWXP6pufn6"},"outputs":[],"source":["import timm\n","from pprint import pprint\n","model_names = timm.list_models(pretrained=True)\n","pprint(model_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5rJZeE-NPzV"},"outputs":[],"source":["model = timm.create_model('dpn92')\n","model"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["tTiBWIBm2Jbn","qHMVKqcIdm8A","w88C3570duAm","Fq43YkDIdxuy","kaZnh628NSXt"],"machine_shape":"hm","provenance":[],"mount_file_id":"1oNvFf3p7--DelmbYGipVwryp1xzArEGa","authorship_tag":"ABX9TyNXYJt8VXMTF2zKTRXhguK5"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}